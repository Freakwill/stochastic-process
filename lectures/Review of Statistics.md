# Review of Probability Theory & Statisitics

[TOC]

*Keywords* Statistics, Probability, Parameter estimation, Bayesian Method


## Measure theory

Probability theory == applied measure theory

### Measurable sp.

**Definition(Measurable sp.)**
$(X,\mathcal{A})$: measurable sp.（$\sigma$-algebra）

1. ...
2. ...
3. ...

*Remark* $\mathcal{A}$: Boolean (sub) algebra on sets (of the power set)

*Definition*
measurable mapping: $f: X\to Y$ (morphism)
measurable function: $f: X\to\overline{\R}$
measurable sp. generated by sets: $\sigma(\{A_i\})$
measurable sp. generated by measurable mapping: $\sigma(f):=\sigma\{f^{-1}(A), A:Y\}$


<center>Tab. Analogy between measure sp. and topology sp.</center>

| measure theory           | topology theory         |
| ------------------------- | ----------------------- |
| $\sigma$-algebra          | topology                |
| measurable sp.            | topological sp.         |
| measurable function/map   | continuous function/map |
| $B(\R)$ Borel measurable sp. | $\R$ ordinary top.      |
| measurble sets            | open sets      |

### Measure

**Definition[measure space]**

$(X,\mathcal{A},\mu)$: measure sp.（$\mu$:measure)

sub-types of measure sp.: 

- ($\sigma$-)finit measure sp., probability sp.
- Lebesgue measure sp. Borel measure sp. Radon measure sp., Dirac measure, discrete/counting measure

Construction of measure:
- product measure, pushforward measure
- pushforward measure $\mu_f(B)=\mu f^{-1}(B)$, $f:(X,\mathcal{A})\to (Y,\mathcal{B})$, $B\in \mathcal{B}$
- distribution: $F(c)=\mu(|f|>c)$

### Integral

integrate $\int_Af(x)\mathrm{d}\mu(x)$

or $\int_Af(x)\mu(\mathrm{d}x)$ or $\mu(f)$ or $\int f$, if there is no ambiguity.

integrable (sp.) $\inf|f|<\infty$

Lebesgue sp. $L^p$

### Examples

Lebesgue measure sp. $\R,\R^n$, the Lebesgue measure denoted as $m,\mathrm{d}x$

## Probability theory

The concepts of probability theory that has to be understood.

### Concepts

#### Probability sp./ Probability model

**Definition(Probability sp.)**
$(\Omega,\mathcal{A},P)$: Probability sp.，$P$: **Probability (measure)**, measure sp. with $P(\Omega)=1$

- sample sp.: $\Omega$
- atomic event: $\omega\in\Omega$ (or the minimal measurable set containing $\omega$)
- event: $A\in \mathcal{A}$ ($\sigma$-algebra)
- $P$: probability (measure)

*Example* classical prob. sp. ($(\{1,\cdots, n\},P(X=k):=\frac{1}{n})$)

**(real-valued) random variable** $X$: measurable function $:\Omega\to \overline{\R}$.

$P(X\in A)=P\{\omega\in\Omega| X(\omega)\in A\}$ where $X\in A\subset \overline{\R}$ <==> $\{\omega\in\Omega| X(\omega)\in A\}$.

**Definition(distribution)** (*pushforward measure* of prob.): $F(x)=P(X\leq x)=P\{X(\omega)\leq x\}=P_X(-\infty,x]$
pushforward probability sp. $(\mathcal{X}, F)$, probability sp. describing rv $X$.

**density function**: $p(x)=F'(x)$

description of rv: $X\sim F$ or $p$.

**joint distr.** $F(x_1,\cdots, x_n)=P(X_1\leq x_1,\cdots,X_n\leq x_n)=P_X((-\infty,x_1]\times\cdots(-\infty,x_n])$

**joint desity** $p(x_1,...,x_n)$

*Remark* The expression $p(x)$ means the proba of $X=x$, that is not restict but convenient, should be written as $p_X(x)$ or $P(X=x)$ if need. notice that the name of a variable dose not carries the meaning, in a natural way. It is just a convention in probability theory. The bigenners should be never confused by such notations.

| measure theory          | probability theory               |
| ----------------------- | -------------------------------- |
| measurable sp.          | ambient sp./ universal event sp. |
| $\sigma$-algebra        | event sets                       |
| measurable set          | event                            |
| measurable function/map | rvs                              |
| measure                 | probability                      |
| pushforward measure     | distribution                     |
| integral/integrable     | Expectation(/finite)             |
| sq. integrable          | variance(/finite)                |
| almost everywhere/a.e.  | almost sure(a.s.)                |

#### Expectation

Expectation: $EX$, ($X$: integrable, $E|X|<\infty$)

$EX:=\int_\Omega X=\int_\R xp(x)\mathrm{d}x=\int_\R x \mathrm{d}F(x)$

$Var(X):=E(X-EX)^2=EX^2-EX^2$
$cov(X, Y):=E(X-EX)(Y-EY)=E(XY)-EXEY$
$Cov(X):=\{cov(X_i,X_j)\}$, $X$: random vector

*Fact.*
$Ef(X)=\int f(x)p(x)\mathrm{d}x=\int f(x)\mathrm{d}F(x)$, where $f$: measurable
$E1_A(X)=P(X\in A)$, where $1_A$ is the indicator on $A$

### Common Distributions

|Name|Symbol|density|
|---|---|---|
|Uniform distr. | $U[a,b]$ | $1$ |
|Bernoulli distr. | $B(p)$ | $P(x=0)=p,P(x=1)=1-p$|
|Binominal/Multinominal distr.| $Bi(n,p)$ |-|
|Normal distr. | $N(\mu,\sigma^2)$ | $p(x)\sim e^{-x^2/2\sigma^2}$|
|Poisson distr. | $P(\lambda)$| $\frac{\lambda^{-k}}{k!}$|
|Categorical distr. | $Cat(p)$ | - |

### Examples

#### coin

![coin](https://img1.baidu.com/it/u=2496111639,4089519478&fm=253&fmt=auto&app=138&f=JPEG?w=499&h=251)

rv: coin/state of coin
sample sp. $\mathcal{X}=\{0,1\}$  (abmient sp.)
(generic rv)$X\sim B(p)$ or (population)$P(X)=B(X;p)$

#### Dice model:game_die:

classical sp. $D=\{1,2,3,4,5,6\}$

![dice](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQna-oCK2sYgR4GhZcttjnwpRNeWNnA0SrsGQ&usqp=CAU)

Bet big and bet small: $D^3$, prod. of $D$
play the dices: $d\sim U(D^3)$

small :={(1,2,3),(1,3,2),...(2,3,4)}
big := ...
others := ...

loss of bet big, $X:=\begin{cases}0,d\in big,\\ -1, d\in small,\\-2, d\in others\end{cases}$

distr. of $X$: $p(0)=P(X=0)\sim N(big),p(-1)=P(X=-1)\sim N(small),p(-2)=P(X=-1)\sim N(others)$


#### [Buffon Needle](https://mste.illinois.edu/activity/buffon/)

$\Omega$={results of dropping a needle}
$\mathcal{X}=[0,1]\times[0,\pi]$
r.v. $X=(d,\theta)$, $d\sim U[0,1], \theta\sim U[0,\pi]$;

$X$ intersects with lines: $d\leq \frac{1}{2}\sin\theta$

$P(d\leq \frac{1}{2}\sin\theta)=E1_{d\leq \frac{1}{2}\sin\theta}(X)\sim area \{d\leq \frac{1}{2}\sin\theta\}$

![Buffon needle](https://www.pepijnvanerp.nl/wordpress/wp-content/uploads/2018/08/buffon-needle2.jpg)

#### Image Process

1. pixles in a an image: sample sp. :$[0,255]^{3ab}$
2. image in image dataset such as ImageNet: sample sp.: $[0,255]^{3mn}$

### Conditional Prob.

$P(A|B):=\frac{P (A\cap B)}{PB}$

if B happens, then A happens.

map $A\mapsto P(A|B)$ is a prob.

**Definition(conditional distr)**
conditional density/distr.

$$p(x|y):=\frac{p(x,y)}{p(y)},  F(x|y):=\frac{\int_{-\infty}^xp(t,y)\mathrm{d}t}{p(y)}$$

if $y$ is fixed, $x\mapsto p(x|y)$: density, $x\mapsto F(x|y)$: distr.

P(X=x|Y=y)

*Discussion*
What if the density function $p(x,y)$ does not exist?（ie. F(x,y): A.C.）


*conditional expectation*


$E(X|Y=y)=\int xp(x|y)=\int x\mathrm{d}F(x|y)$ **regression function**

$E(X|Y):E(X|y)\circ Y$ conditional expection

**identity of C.E.**
$E(E(X|Y))=EX$


*Remark* (Kolmogorov's Conditional Prob.)

$E_AE(X|Y)=E_AX$ where $E(X|Y),A$ is measurable on $\sigma(Y)$
= projection of $X$ on $L^2(\Omega,\sigma(Y))$ if $DX<\infty$

*Discussion* Uniqueness of $E(X|Y)$


Most important fact about condition distr is Bayesian formula

**Theorem(Bayes' Formula)**
$$
p(y|x)=\frac{p(x|y)p(y)}{\int p(x|y)p(y)dy}
$$
- likelihood function: $p(x|y)$
- prior distr.: $p(y)$
- posterior distr.: $p(y|x)$
- total prob: $p(x)=\int p(x|y)p(y)dy$


<center>Tab. Relation between measure theory and prob. theory</center>

| measure theory          | prob. theory            | notations        |
| :---------------------- | ----------------------- | ---------------- |
| measure sp.             | prob. sp.               | $\Omega$         |
| measurable set          | event                   | $A$              |
| measurable function/map | continuous function/map | $X$              |
| integral                | expection               | $E(X)$           |
| pushward measure        | distribution            | $F(x),P(X\in A)$ |
| conditional integral    | conditional expection   | $E(X|Y)$         |



## Statistics

*Keywords* Paramter distribution, Population, Sample, Statistic/Estimator, MLE


The concepts and methods of Statistics applied in SL
measure sp -> prob. sp (distr.) -> stat. model (family/set of prob. model with common sample sp.)

### Concepts

**Def Stat. models**
$(\Omega,\mathcal{A},\{P_{\lambda}\})$ or $(\mathcal{X},\{p_{\lambda}(X)\})$
  - nonparametric $(\mathcal{X},p(X), p\in\mathcal{P})$
  - parametric $(\mathcal{X},p(X|\theta), \theta\in\Theta)$ where $\Theta$ is parameter sp.

*Remark* in parametric form, $\Theta\subset\R^d$ that dose not have to be obeyed here, since we don't limite the form of parameter sp.

**population**: $F_\theta$

**generic/target rv**: $X\sim F_\theta$

**sample(data)**: $X_i\sim F_\theta,i=1,\cdots,N, iid$

**statistic**: $T(X)$ where $X=\{X_i\}$ is a sample, called an estimator if it is designed to estimate parameters, as $\hat{\theta}(X)$.

### Main tasks 
1. parameter estimation: $\hat{\theta}(X)$
2. prediction: $\hat{X}(\hat{\theta})$ (or $\theta$ is known)
3. sampling/generating/simulation: $X\sim F_{\hat{\theta}}$

### Bayesian Model

**Def Bayesian Model**
a pair of prob $P(X|\theta), P(\theta)$, <==> $P(X,\theta)$

where unknown param. $\theta$ is treated as a unobservable rv/latent var.

#### conjugate prori

**Definition**

$p(\theta|x)$ and $p(\theta)$ in the same distr. family.

For distr. family, $p(\theta|\alpha)$, we have
$$
p(\theta|x)=p(\theta|\alpha_1)=p(x|\theta)p(\theta|\alpha_0)
$$
and get an iteration, says, $\alpha_1=T(x,\alpha_0)$.


*Remark* In general case, we get the accurate value of $\alpha$, but can not determine the value of $\theta$.


### Parameter Estimation

The main task of statistics or machine learning is parameter estimation.

**unbiased estimator**: $E\hat{\theta}(\{X_i\})=\theta$ where $X_i\sim F_\theta$,iid

**MVUE/LBUE/AUE**


#### MLE 

**maximization likelihood estimator (MLE)** is the standard method in SL/ML.

**likelihood function** Given model $p(x|\theta)$
$$
l(\theta;x):=\log p(x|\theta)
$$
for i.i.d. samples $l(\theta):=\sum_i\log p(x_i|\theta)$. (sample likelihood)

**MLE**
estimate $\theta$ by
$$
\max_\theta\{l(\theta):=\sum_i\log p(x_i|\theta)\}
$$

*Fact*
If the real distr $p_{0}$ and $p(x|\theta)$ is a model, then
$$
-\frac{1}{N}l(\theta)\approx  H(p_{0},p(x|\theta))\\
\sim D_{KL}(p_{0}\|p(x|\theta))
$$
negative-average-likelihood ~ cross entropy between real distr. and model distr.


*Example* 
Gaussian distr. $X\sim N(\mu,\sigma^2)$, with (unkown) $\mu$ or $\sigma^2$

MLE is the minimal of $-l(\mu,\sigma^2)\sim N\log \sigma^2+\sum_i(x_i-\mu)^2/\sigma^2$

*Discussion*
MLE of parameters of mixture Guassian distr. $p(x|\{p_c\},\{\mu_c\},\{\sigma^2_c\})=\sum p_c\phi(x|\mu_c,\sigma^2_c), \sum_cp_c=1,p_c>0$.

#### MAPE
Bayes estimate (Bayes formula), require posterior distr. $p(\theta|x)\sim p(\theta)p(x|\theta)$

maximum A posteriori(MAP): $\hat{\theta}=\argmax_\theta p(\theta|x)$

*Fact*
MAPE = MLE + regularization

### Full Form of Stat Model
$(M_\theta,\hat\theta(X))$
where $M_\theta$ is the model, and $\hat\theta(X)$ is the estimator of $\theta$.

### Statistical Decision
let $l(x,\theta)$ is a loss (of $\theta$ at the point $x$). Define (expected) risk
$$
J(\theta) := El(X,\theta), X\sim P
$$
and empirical risk (for unknown $P$)
$$
\hat{J}(\theta;\{X_i\}) := \frac{1}{N}\sum_il(X_i,\theta)
$$

ERM: $\min_\theta \hat{J}(\theta)$

*Fact*
MLE = ERM with negative likelihood loss $l(x,\theta)=-\ln p(x|\theta)$

#### Model Selection
Is the sample $X$ drawn from $\mathcal{F}$ or $\mathcal{G}$?

$\min_{p\in \mathcal{F}} J(p)<\min_{p\in \mathcal{G}} J(p)$
<==> $\min_{p\in \mathcal{F}\cup\mathcal{G}} J(p)$

#### Hypothesis test
$H_0:\theta\in\Theta_0$  vs $H_1:\theta\in\Theta_1$ where $\Theta_0\cup \Theta_1=\Theta$


- **Error I（FP）**: reject $H_0$, when $H_0$ holdes
- **Error II (FN)**: accept $H_0$ when $H_0$ dose not hold。

null hypothesis principle:
$$
\begin{cases}
  reject~ H_0(accept ~H_1),& X\in W\\
  accept~ H_0,& else
\end{cases}
$$
where $W$ is the rejection domain.

Test is a 0-1 stat decision:
$$
l(\theta, X):=\begin{cases}1, & X\in W,\theta\in\Theta_0\\
c,& X\notin W,\theta\in\Theta_1\\
0, & \text{else}
\end{cases}
$$
where $1\geq c>0$(protect hull hypo).
**Power function**:
$$
\alpha(\theta):=P(X\in W|\theta),\theta\in\Theta
$$
the p-value of $X$(under $\theta\in\Theta_0$).

**Principle**：minimize Error I by $\sup_{\theta\in\Theta_0}\alpha(\theta)\leq \alpha$，minimize Error II based on it，$\alpha$ is called the **significance level**(e.g. 0.01).

*Example* $X\sim N(\mu, 1)$, $H_0:\mu=\mu_0$
$X\in W$ iff $P(X|\mu_0)<\frac{\alpha}{2}$ iff $X<\Phi_{\frac{\alpha}{2}}$ or $>\Phi_{1-\frac{\alpha}{2}}$

#### Confident Interval

$\hat\theta(X)-\theta\sim P$

$C(X)=[\hat\theta(X)-a,\hat\theta(X)+b]$ such that $P(\theta\in C(X))$

### Bayes method & Hyper-parameters 

####  Marginal Likelihood

Priori of $\theta$ with an unknown hyper-parameter $\alpha$, i.e. $p(\theta|\alpha), \alpha\sim 1$ and $\alpha\perp x|\theta$



M.L. of $\alpha$ = marginal distr. of $p(x,\theta|\alpha)$, joint distr of $x, \theta$ under $\alpha$
$$
p(x|\alpha)=\int p(x,\theta|\alpha)\mathrm{d}\theta=\int p(x|\theta)p(\theta|\alpha)
$$
Get the MLE of the hyper-parameter $\alpha$, $\hat{\alpha}_{ML}=\arg\max_\alpha p(x|\alpha)$, named MMLE in the context.

Now we have an estimator of priori of $\theta$, i.e. $p(\theta|\hat{\alpha}_{ML})$, then get the posterior distr. of $\theta|x$, using Bayesian formula, ie.  $p(\theta|x)\sim p(x|\theta)p(\theta|\hat{\alpha})$.


#### Bayesian method for Hyper-parameters

PGM: $\alpha\to \theta\to x$

$$
p(\theta |x)\propto p(x,\theta)=\int p(x|\theta)p(\theta|\alpha)p(\alpha)d\alpha
$$

### Variational Stat.

$$
D(q(\theta)\| p(\theta|X))\sim D(q\| p)+ E_{\theta\sim q}l(\theta)
$$


### Prediction/Error

Prediction：minimize $l(X,\hat{X})$ where $l$ is a loss/error $\hat{X}$ is nonstochastic. Since $X\sim P$ is stochastic, then we use prediction error:
$$
PE(\hat{X}):=El(X,\hat{X})
$$

In fact $\hat{X}(S)$ is a statistics of $S\sim P$. Define **generalization error**：
$$
EPE:=E(PE)
$$

**sample/empirical error**：$\widehat{EPE}(\hat{X}):=\frac{1}{N}\sum_il(X_i,\hat{X})$，where $X_i\sim P$ when $P$ is unknown。

**Fact(bias-variance-tradeoff)**
Let square loss $l(X,\hat{X})=|X-\hat{X}|^2, X,\hat{X}\in\R^d$。
$$
PE=(EX-\hat{X})^2+var X\\
EPE= (EX-E\hat{X})^2 + var \hat{X} + var X
$$

**unbias prediction**: if bias=0 e.g. $EX=E\hat X$。

For drvs, use 0-1 loss $1_{X\neq \hat{X}}$，and $PE=P(X\neq \hat{X})$
*Fact*
$$
PE=(P_*-P(X=\hat{X})) + (1-P_*)\\
EPE=(P_*-\sum_{x}P(X=x)P(\hat{X}=x))+ (1-P_*)
$$
where $X_*$ is the mode of $X$ and $P_*:=P(X= X_*)$


**Principle**
crv-mean；drv-mode。

*Def* A full stat model, or predictor:
$$
(M, \hat{X}(S))
$$
$M$ is a known stat model.

Prediction as a stat decision：minimize the risk
$$
J(\theta)=El(X,\hat{X}(\theta))\\
\approx \frac{1}{N}\sum_il(X_i,\hat{X}(\theta))
$$

risk based on error/prediction.

**Stat. Inference** = Estimation & Prediction, estimate an unknown quanity based on samples

*Remark* risk/loss/error

### Dependent sample
describe the model by the joint distr. of sample
$$
P(X_1,\cdots,X_N)
$$
whose marginal distr. is the population $P(X_i)$. It is a stat. model definded on $\mathcal{X}^N$.

*Remark* $P^*$ denotes such joint distr.

## Information Theory

### Entropy

*Definition*
$X\sim p$, define
$$
H(X)=H(p):=-\int p(x)\log p(x)dx
$$
where $p$ could be any nonnegative integrable function.

entropy of sample $S=\{x_i,i=1,\cdots,N\}$:
$$
H(S):=-\frac{1}{N}\sum_k N(x_i=k)\log \frac{N(x_i=k)}{N}\\
\sim -\sum_k N(x_i=k)\log N(x_i=k)
$$

*remark* for drv, NLL = sample entropy

Conditional Entropy: entropy of conditional distr. $p(y|x)$

*Fact*
$H(X|Y)=H(XY)-H(Y)$

### Cross Entropy
**Definition** cross entropy

$X\sim p, Y\sim q$, define
$$
H(X,Y)=H(p,q):=-\int p(x)\log q(x)
$$

by LLN, $H(p,q)\approx -\sum_i\log q(x_i)=-l(q)$.

for $X\sim p$ where p is unknown, $H(X)\approx H(p,q)\approx-l(q)$.

**Definition** KL divergence (distance)
$$
D_{KL}(p,q):=\int p(x)\log \frac{p(x)}{q(x)}
$$

**Definition** sample/empirical distr.
$$
\delta_S=\frac{1}{N}\sum_i\delta_{X_i}
$$
where $S=\{X_i\}$ is the sample.

*Fact*
MLE ==> $p$ approximates $p_0$ (under $D_{KL}$)
$-l(p)\sim D_{KL}(\delta_S\|p)\approx D_{kL}(p_0\|p)$

"Distance Minimization Estimation": $d(\delta_S,p)\approx d(p_0,p)$ where $d$ is the distance between two distr. $d(\delta_S,p)$ is the "plug-in estimation" of $d(p_0,p)$.

### Mutual Information
$I(X;Y)=H(X)+H(Y)-H(XY)=H(X)-H(X|Y)=H(Y)-H(Y|X)$

Conditional MI: $I(X;Y|Z)$

## Summary

- basic theory: real analysis, proba. theory
- definition stat. model
- method: MLE
- Information theory. KL-div ~ MLE

---

*Homework*
1. Zip-law $X\sim Zip(\lambda, \sigma)$
$$P(X=x)\sim e^{-\lambda\sigma(x)},\sigma\in S(\mathcal{X}),\mathcal{X}=\{1,\cdots,N\}
$$
MLE of $\lambda,\sigma$.

2. Bertrand Paradox
![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Bertrand3-translate_ru.svg/320px-Bertrand3-translate_ru.svg.png)

3. Stat. decision for ML $y\sim f(x)$

4. prove $E(X-Y)^2=(EX-EY)^2+var X+var Y$, where $X\perp Y$. (Bienaymé identity)
   
5. **Safe first criteron**SF-loss $l(x,w):=1_{x\cdot w\geq d},x\in\R^p,w\in \Delta^{p-1}$, where $d$ is the catastrophic level，$w$ is the unknown parameter(weights of portfolio). Show the risk and the estimation method of $w$.
6. Given the abstract value loss $l(x,\hat{x}):=|x-\hat{x}|$, show the risk and the similar bias-variance tradeoff. What about the asymetric case:
$$
   l(x,\hat{x})=\begin{cases}
   (1-\tau)(\hat{x}-x),& x<\hat{x},\\
   0,& x=\hat{x},\\
   \tau(x-\hat{x}),& x>\hat{x}
   \end{cases}
   $$ 
   where $\tau\in(0,1)$.

*Reference*


P. J. Bickel, K. A. Doksum. Mathematical Statistics---Basic ideas and selected topics, 2015.

J. Shao, Mathematical Statistics, 2003.

S. N. Wood. Core Statistics, 2018.

[Statistics How To](https://www.statisticshowto.com/)

[Distributions](https://distribution-explorer.github.io/index.html)
